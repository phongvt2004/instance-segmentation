{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import os\n",
    "import urllib.request\n",
    "import zipfile\n",
    "import shutil\n",
    "\n",
    "def download_coco(destination_folder):\n",
    "    os.makedirs(destination_folder, exist_ok=True)\n",
    "    \n",
    "    urls = {\n",
    "        \"train\": \"http://images.cocodataset.org/zips/train2017.zip\",\n",
    "        \"val\": \"http://images.cocodataset.org/zips/val2017.zip\",\n",
    "        \"test\": \"http://images.cocodataset.org/zips/test2017.zip\",\n",
    "        \"annotations\": \"http://images.cocodataset.org/annotations/annotations_trainval2017.zip\"\n",
    "    }\n",
    "    \n",
    "    for key, url in urls.items():\n",
    "        zip_path = os.path.join(destination_folder, f\"{key}.zip\")\n",
    "        if not os.path.exists(zip_path):\n",
    "            print(f\"Downloading {key}...\")\n",
    "            urllib.request.urlretrieve(url, zip_path)\n",
    "        \n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(destination_folder)\n",
    "    \n",
    "    print(\"COCO dataset downloaded and extracted.\")\n",
    "\n",
    "def create_coco_subset(original_json_path, output_json_path, image_folder, output_image_folder, fraction=0.5):\n",
    "    # Load the original COCO dataset\n",
    "    with open(original_json_path, 'r') as f:\n",
    "        coco_data = json.load(f)\n",
    "    \n",
    "    # Extract images and annotations\n",
    "    images = coco_data['images']\n",
    "    annotations = coco_data['annotations']\n",
    "    \n",
    "    # Select a random subset of images\n",
    "    num_images = len(images)\n",
    "    selected_images = random.sample(images, int(num_images * fraction))\n",
    "    selected_image_ids = {img['id'] for img in selected_images}\n",
    "    \n",
    "    # Filter annotations corresponding to the selected images\n",
    "    selected_annotations = [ann for ann in annotations if ann['image_id'] in selected_image_ids]\n",
    "    \n",
    "    # Create new dataset\n",
    "    subset_coco_data = {\n",
    "        \"info\": coco_data.get(\"info\", {}),\n",
    "        \"licenses\": coco_data.get(\"licenses\", {}),\n",
    "        \"categories\": coco_data.get(\"categories\", {}),\n",
    "        \"images\": selected_images,\n",
    "        \"annotations\": selected_annotations\n",
    "    }\n",
    "    \n",
    "    # Save subset dataset\n",
    "    with open(output_json_path, 'w') as f:\n",
    "        json.dump(subset_coco_data, f, indent=4)\n",
    "    \n",
    "    # Copy selected images to new folder\n",
    "    os.makedirs(output_image_folder, exist_ok=True)\n",
    "    for img in selected_images:\n",
    "        src_path = os.path.join(image_folder, img['file_name'])\n",
    "        dst_path = os.path.join(output_image_folder, img['file_name'])\n",
    "        if os.path.exists(src_path):\n",
    "            shutil.copy(src_path, dst_path)\n",
    "    \n",
    "    print(f\"Subset saved to {output_json_path} with {len(selected_images)} images and {len(selected_annotations)} annotations.\")\n",
    "\n",
    "# Example usage\n",
    "datasets = ['train', 'val', 'test']\n",
    "download_folder = '/path/to/coco/'\n",
    "download_coco(download_folder)\n",
    "original_base_path = os.path.join(download_folder, 'annotations/')\n",
    "output_base_path = '/path/to/coco_subset/'\n",
    "\n",
    "os.makedirs(output_base_path, exist_ok=True)\n",
    "\n",
    "for dataset in datasets:\n",
    "    create_coco_subset(\n",
    "        original_json_path=os.path.join(original_base_path, f'instances_{dataset}2017.json'),\n",
    "        output_json_path=os.path.join(output_base_path, f'annotations/instances_{dataset}_subset.json'),\n",
    "        image_folder=os.path.join(download_folder, f'{dataset}2017/'),\n",
    "        output_image_folder=os.path.join(output_base_path, f'images/{dataset}2017_subset/')\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
